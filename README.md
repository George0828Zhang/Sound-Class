# Sound-Class
Sound classification using convolution neural network

## How to execute
There are 5 programs included in this project, which are *`GenSpectrogram.py`,`predict.py`,`LeNet5.py`,`AlexNet.py`* and *`VGG.py`.*
A *`Makefile`* is created for easier execution of the programs.
### Required Package
- *`opencv`*: The programs use *`cv2`* module to read, store, normalize and resize the spectrograms.

### All-in-one
To directly obtain *`model.h5`* and *`results.npy`* from the folders *`train/`,`val/`*,run
:::info
＄make spectro run
:::
### Generate Spectrograms
To generate spectrograms from data stored in folders`train/`,`val/`, run
:::info
＄make spectro
:::
- This will create 2 folders containing spectrograms *`train2/`,`val2/`.*

### Training and Predicting
To train a model *`model.h5`* from spectrograms in *`train2/`* using architecture *`$(net)`*, run
:::info
＄make train NET=$(net)
:::
- *`NET`*: one of *`LeNet5.py`,`AlexNet.py`* or *`VGG.py`.* Defaults to *`AlexNet.py`.*

To predict labels of *`test.npy`* with *`model.h5`* and save to *`results.npy`*, run
:::info
＄make predict
:::

To predict with other models *`$(model)`* and save to *`$(save)`*, run
:::info
＄make predict MOD=\$(model) RES=$(save)
:::


## Settings
### Global
- hamming window
- use magnitude only
- 0-255 (normalized using *`opencv`*'s normalize)
- 64 $\times$ 64 (resized using *`opencv`*'s resize)

### Spectrogram settings

|  Settings | A  | B  | C  |
|---|---|---|---|
|  Window Length | 128  | 256  | 256 |
|  Overlap Length | 16 (12.5%)  | 32 (12.5%) | 64 (25%)  |

### CNN settings

|  Settings | Optimizer | Batch Norm | Dropout |  Batch size | Epochs | Input  | Output | 
|---|---|---|---|---|---|---|---|
|  LeNet-5 | Adam  `lr=0.004`  | None  | None | 256  |60|64 $\times$ 64|20|
|  AlexNet | SGD `lr=0.01` `mo=0.9` `dc=1e-6` | 1^st^,2^nd^ Pooling  | 0.5, Dense |128  |30|64 $\times$ 64|20|
|  VGG-16 | SGD `lr=0.01` `mo=0.9` `dc=1e-6` | None  | 0.5, Dense |128  |30|64 $\times$ 64|20|

- `lr`: learning rate
- `mo`: momentum
- `dc`: learning rate decay
- initialization: all randomly

## Accuracy (Validation Set)

|  Accuracy(%) | A  | B  | C  |
|---|---|---|---|
|  LeNet-5 | 98.36  | 99.05  | 98.92  |
|  AlexNet | 98.88  | 98.80  | 98.92  |
|  VGG-16 | 98.88  | 97.50  | 98.11  |

## Obtaining the result
### Adding validation
In addition to the 9 models trained, I train 2 new models for each of the 3 network architectures with training data combined with validation data, and using spectrogram setting A and B.

### Voting for result
With 15 models, we obtained the final *`results.npy`* by voting. Each sample in *`test.npy`* has 15 predicted labels. Voting is done by the following procedure.
- The label with ++highest count++ out of the 15 wins. If there is a draw, leave the answer undetermined. 
- For each determined label, ++increase importance++ of the models with correct labels.
- ++Assign the labeling++ of the most important model to the undetermined labels.

### Divergence
Finally the difference between the final result and the results from the 15 models are evaluated to make sure that they are not too far apart. 

|  Error(%) | A  | B  | C  | A(+v)  | B(+v)  |
|---|---|---|---|---|---|
|  LeNet-5 | 4.32  | 2.89  | 3.14  |3.10|2.64|
|  AlexNet | 2.01  | 2.51  | 3.69  |3.23|1.84| 
|  VGG-16 | 2.76|3.27|2.18|2.47|2.09|

### Submission
Based on this information, *`AlexNet(A)`* and *`AlexNet(B+v)`* should be the most reliable models. However, since the latter is trained with validation set, it is selected to be submitted.
- The submitted files are:
    * *model.h5*: AlexNet model
    * *result.npy*: Results generated by *model.h5*
    * *result_voting/results.npy*: Results generated by ++voting++.

## What I learned
- Because I'm using AMD gpu, in order to use tensorflow-gpu I had to install rocm stack and tensorflow-rocm.
- Ability to understand/use keras.
- Architecture of CNNs such as *LeNet-5, AlexNet* and *VGG*.
- Implementation details such as optimizers and parameters for optimizers.
- I have experimented on other settings:
    * `224 x 224`input: Much higher computational cost, and little improvements on validation accuracy. 
    * *phase* as 2^nd^ channel: Requires more iterations to converge on in-sample error, and it somehow increases validation set error.
- Shallow networks like *LeNet-5* can achieve acceptable results in validation set, and the trainning is extremely fast. However, *AlexNet* and *VGG-16* are deeper and more complex, and thus might be more suited for predicting labels of new unseen signals. 

## References
- Gradient-Based Learning Applied to Document Recognition, Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner.
- ImageNet Classification with Deep Convolutional Neural Networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton.
- Very Deep Convolutional Networks for Large-Scale Image Recognition, Karen Simonyan, Andrew Zisserman.

